# Tutorial 2{#sec:T2}

## Q1 

* Derive moments from a given pdf $f(x)$. $EX = \int xf(x)dx, EX^2=\int x^2f(x)dx$.

* Derive variance from the first and second moments,i.e., $Var(X)=EX^2-E^2X$.

* $E(aX+bY+c) = aEX + bEY+c$, $Var(aX+bY+c) = a^2Var(X)+b^2Var(Y)$. The latter needs $X$ and $Y$ are independent.

* CLT approximation.

## Q2

```{definition, name = "Poisson Process"}
Let $N(t)$ be the number of events happens during the time interval $[0,t]$, if $N(t)$ satisfies the following:
  
- N(0) = 0;
- has independent increments, and
- $\forall \tau>0$, $P(N(t+\tau)-N(t) = n)= \frac{(\lambda \tau)^n}{n!}e^{-\lambda \tau}$
  
we call $\{N(t),t\geq0\}$ is a Poisson process with rate $\lambda$.
```

* Let $(W_n>t)$ be the $n-th$ random event happens after time $t$, then $W_n\sim Gamma(n, \lambda)$. In fact, $Gamma(n,\lambda)$ can be seen as the time to be waited until the $n-th$ event.

## Q3 

```{proposition}
Suppose the random variable $X$ has a pdf $f(x)$, let $Y = T(X)$, where $T:\mathbb{R}\rightarrow \mathbb{R}$ is an invertible transformation. Then the pdf $g(y)$ of $Y$ is 
\begin{equation*}
g(y) = f(T^{-1}(y))\frac{d T^{-1}(y)}{dy}
\end{equation*}
```

For example, suppose $X\sim\mathcal{N}(\mu,\sigma^2)$, then $Y=aX+b\sim\mathcal{N}(a\mu+b, (a\sigma)^2)$.

## Q4

```{theorem, name = "Chebyshev's Inequality"}
Let $X$ be a random variable with finite mean $\mu$ and variance $\sigma^2>0$. Then $\forall k>0$, 
\begin{equation*}
P(|X-\mu|\geq k\sigma) \leq \frac{1}{k^2}
\end{equation*}

Additionally, let $k\sigma = \varepsilon$, the above becomes, 
\begin{equation*}
P(|X-\mu|\geq \varepsilon) \leq \frac{\sigma^2}{\varepsilon^2}
\end{equation*}
```


  